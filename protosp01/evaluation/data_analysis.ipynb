{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### green ###############\n",
      "                             train        test          all\n",
      "size                   8668.000000  335.000000  9003.000000\n",
      "avg_sentence_length      23.265805   22.940299    23.253693\n",
      "avg_nb_skills             1.330641    2.005970     1.355770\n",
      "max_nb_skills            24.000000   17.000000    24.000000\n",
      "percent_without_skill    40.759114   30.447761    40.375430\n",
      "avg_span_length           5.647831    2.685889     5.525317\n",
      "############### skillspan ###############\n",
      "                             train         test          all\n",
      "size                   4782.000000  3569.000000  8351.000000\n",
      "avg_sentence_length      18.275826    11.988232    15.588672\n",
      "avg_nb_skills             0.424509     0.305688     0.373728\n",
      "max_nb_skills            15.000000    11.000000    15.000000\n",
      "percent_without_skill    79.401924    83.636873    81.211831\n",
      "avg_span_length           4.121293     3.561679     3.916752\n",
      "############### fijo ###############\n",
      "                            train       test         all\n",
      "size                   399.000000  50.000000  449.000000\n",
      "avg_sentence_length     21.132832  31.700000   22.309577\n",
      "avg_nb_skills            1.804511   2.460000    1.877506\n",
      "max_nb_skills           17.000000  11.000000   17.000000\n",
      "percent_without_skill    3.759398  16.000000    5.122494\n",
      "avg_span_length          9.265272   9.700728    9.308204\n",
      "############### sayfullina ###############\n",
      "                             train         test          all\n",
      "size                   3705.000000  1851.000000  5556.000000\n",
      "avg_sentence_length      14.330634    14.353863    14.338373\n",
      "avg_nb_skills             1.003239     1.003241     1.003240\n",
      "max_nb_skills             3.000000     2.000000     3.000000\n",
      "percent_without_skill     0.107962     0.108050     0.107991\n",
      "avg_span_length           1.690655     1.752126     1.711552\n",
      "############### kompetencer ###############\n",
      "                            train        test          all\n",
      "size                   778.000000  262.000000  1040.000000\n",
      "avg_sentence_length     14.489717   13.164122    14.155769\n",
      "avg_nb_skills            0.520566    0.400763     0.490385\n",
      "max_nb_skills           13.000000   14.000000    14.000000\n",
      "percent_without_skill   77.763496   83.206107    79.134615\n",
      "avg_span_length          3.335128    3.790675     3.430034\n",
      "############### gnehm ###############\n",
      "                              train         test           all\n",
      "size                   19824.000000  2550.000000  22374.000000\n",
      "avg_sentence_length       10.244249    10.779608     10.305265\n",
      "avg_nb_skills              0.386047     0.349412      0.381872\n",
      "max_nb_skills             26.000000    19.000000     26.000000\n",
      "percent_without_skill     83.106336    82.823529     83.074104\n",
      "avg_span_length            1.298646     1.322713      1.301364\n"
     ]
    }
   ],
   "source": [
    "path = \"../../data/annotated/processed/\"\n",
    "metrics = ['size', 'avg_sentence_length', 'avg_nb_skills', 'max_nb_skills', 'percent_without_skill', 'avg_span_length', 'total_unique_skills', 'skill_overlap']\n",
    "res_df = pd.DataFrame(columns=['dataset'] + metrics)\n",
    "for dataset_name in ['green', 'skillspan', 'fijo', 'sayfullina', 'kompetencer', 'gnehm']:\n",
    "    print(\"###############\", dataset_name, \"###############\")\n",
    "    test = pd.read_json(os.path.join(path, dataset_name, 'test.json'))\n",
    "    train = pd.read_json(os.path.join(path, dataset_name, 'train.json'))\n",
    "    all = pd.concat([test, train])\n",
    "    dataset_metrics = {}\n",
    "    for split_name, split in {'train':train, 'test':test, 'all':all}.items():\n",
    "        # avg sentence length\n",
    "        split['sentence_length'] = split['tokens'].apply(lambda x: len(x))\n",
    "        avg_sentence_length = split['sentence_length'].mean()\n",
    "        # nb of skills per sentence\n",
    "        split['nb_skills'] = split['list_extracted_skills'].apply(lambda x: len(x))\n",
    "        avg_nb_skills = split['nb_skills'].mean()\n",
    "        max_nb_skills = split['nb_skills'].max()\n",
    "        nb_negative = len(split[split['nb_skills'] == 0]) / len(split) * 100\n",
    "        # avg span length\n",
    "        split['avg_span_length'] = split['skill_spans'].apply(lambda x: np.mean([span[1][1] - span[1][0] for span in x]) if len(x) > 0 else 0)\n",
    "        avg_span_length = np.mean([length for length in split['avg_span_length'] if length != 0])\n",
    "\n",
    "        dataset_metrics[split_name] = {'size': len(split), 'avg_sentence_length': avg_sentence_length, 'avg_nb_skills': avg_nb_skills, 'max_nb_skills':max_nb_skills, 'percent_without_skill':nb_negative, 'avg_span_length': avg_span_length}\n",
    "    print(pd.DataFrame(dataset_metrics))\n",
    "    # overall metrics:\n",
    "    # nb of unique skills in the whole split\n",
    "    all_unique_skills = all.explode('list_extracted_skills')['list_extracted_skills'].unique()\n",
    "    # skill overlap\n",
    "    test_unique_skills = test.explode('list_extracted_skills')['list_extracted_skills'].unique()\n",
    "    train_unique_skills = train.explode('list_extracted_skills')['list_extracted_skills'].unique()\n",
    "    skill_overlap = len(set(train_unique_skills).intersection(set(test_unique_skills))) / len(all_unique_skills) * 100\n",
    "    dataset_res = pd.DataFrame({'dataset': dataset_name, **dataset_metrics['all'], 'total_unique_skills': len(all_unique_skills), 'skill_overlap': skill_overlap}, index=[len(res_df)])\n",
    "    res_df = pd.concat([res_df, dataset_res])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>size</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>avg_nb_skills</th>\n",
       "      <th>max_nb_skills</th>\n",
       "      <th>percent_without_skill</th>\n",
       "      <th>avg_span_length</th>\n",
       "      <th>total_unique_skills</th>\n",
       "      <th>skill_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>9003</td>\n",
       "      <td>23.253693</td>\n",
       "      <td>1.355770</td>\n",
       "      <td>24</td>\n",
       "      <td>40.375430</td>\n",
       "      <td>5.525317</td>\n",
       "      <td>9974</td>\n",
       "      <td>1.473832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skillspan</td>\n",
       "      <td>8351</td>\n",
       "      <td>15.588672</td>\n",
       "      <td>0.373728</td>\n",
       "      <td>15</td>\n",
       "      <td>81.211831</td>\n",
       "      <td>3.916752</td>\n",
       "      <td>2706</td>\n",
       "      <td>3.178123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fijo</td>\n",
       "      <td>449</td>\n",
       "      <td>22.309577</td>\n",
       "      <td>1.877506</td>\n",
       "      <td>17</td>\n",
       "      <td>5.122494</td>\n",
       "      <td>9.308204</td>\n",
       "      <td>623</td>\n",
       "      <td>2.568218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sayfullina</td>\n",
       "      <td>5556</td>\n",
       "      <td>14.338373</td>\n",
       "      <td>1.003240</td>\n",
       "      <td>3</td>\n",
       "      <td>0.107991</td>\n",
       "      <td>1.711552</td>\n",
       "      <td>983</td>\n",
       "      <td>40.895219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kompetencer</td>\n",
       "      <td>1040</td>\n",
       "      <td>14.155769</td>\n",
       "      <td>0.490385</td>\n",
       "      <td>14</td>\n",
       "      <td>79.134615</td>\n",
       "      <td>3.430034</td>\n",
       "      <td>457</td>\n",
       "      <td>2.625821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gnehm</td>\n",
       "      <td>22374</td>\n",
       "      <td>10.305265</td>\n",
       "      <td>0.381872</td>\n",
       "      <td>26</td>\n",
       "      <td>83.074104</td>\n",
       "      <td>1.301364</td>\n",
       "      <td>4661</td>\n",
       "      <td>5.942931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset   size  avg_sentence_length  avg_nb_skills max_nb_skills  \\\n",
       "0        green   9003            23.253693       1.355770            24   \n",
       "1    skillspan   8351            15.588672       0.373728            15   \n",
       "2         fijo    449            22.309577       1.877506            17   \n",
       "3   sayfullina   5556            14.338373       1.003240             3   \n",
       "4  kompetencer   1040            14.155769       0.490385            14   \n",
       "5        gnehm  22374            10.305265       0.381872            26   \n",
       "\n",
       "   percent_without_skill  avg_span_length total_unique_skills  skill_overlap  \n",
       "0              40.375430         5.525317                9974       1.473832  \n",
       "1              81.211831         3.916752                2706       3.178123  \n",
       "2               5.122494         9.308204                 623       2.568218  \n",
       "3               0.107991         1.711552                 983      40.895219  \n",
       "4              79.134615         3.430034                 457       2.625821  \n",
       "5              83.074104         1.301364                4661       5.942931  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB of unique skill normalized by data size\n",
    "# check max span length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule-based detection of 'bad' sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
