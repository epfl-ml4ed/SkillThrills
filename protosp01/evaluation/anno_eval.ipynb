{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations on Marco's Annotations\n",
    "\n",
    "We first read in the annotations from Marco's files, run the pipeline of those annotations using GPT3.5 and GPT4-turbo, and then evaluate the results.\n",
    "\n",
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(document):\n",
    "    \"\"\"Get extracted skills from each sentence in a document from the detailed output\"\"\"\n",
    "    # extracted_skills_count = 0\n",
    "    # matched_skills_count = 0\n",
    "    matched_skills = []\n",
    "    existing_skills = set()\n",
    "\n",
    "    for sentences in document:\n",
    "        # create zip dict of sentences[\"extracted_skills\"] and sentences[\"extracted_skills_levels\"]\n",
    "        skill_level_dict = dict(\n",
    "            zip(\n",
    "                sentences.get(\"extracted_skills\", [\"\"]),\n",
    "                sentences.get(\"extracted_skills_levels\", [\"\"]),\n",
    "            )\n",
    "        )\n",
    "        # extracted_skills_count += len(skill_level_dict)\n",
    "        matched_skill = sentences.get(\"matched_skills\", {})\n",
    "        # matched_skills_count += len(matched_skill)\n",
    "        for skill_name, skill_info in matched_skill.items():\n",
    "            unique_id = skill_info[\"unique_id\"]\n",
    "            skill_level = skill_level_dict[skill_name]\n",
    "            if unique_id not in existing_skills:\n",
    "                matched_skills.append((unique_id, skill_level, skill_name))\n",
    "                existing_skills.add(unique_id)\n",
    "\n",
    "    return matched_skills  # , extracted_skills_count, matched_skills_count\n",
    "\n",
    "\n",
    "def get_matched_skills(data):\n",
    "    \"\"\"get relevant information on matched skills from the detailed output\"\"\"\n",
    "    clean_output_dict = {}\n",
    "    # extract_skills_dict = {}\n",
    "    # matched_skills_dict = {}\n",
    "\n",
    "    for doc_id, doc_data in data.items():\n",
    "        if isinstance(doc_data, list):\n",
    "            # If the data is a list, directly extract matched skills\n",
    "            clean_output_dict[doc_id] = extract_skills(doc_data)\n",
    "            # clean_output_dict[doc_id], extract_skills_dict[doc_id], matched_skills_dict[doc_id] = extract_skills(doc_data)\n",
    "        elif isinstance(doc_data, dict):\n",
    "            # If the data is a dictionary, check for nested keys\n",
    "            nested_keys = [\"required\", \"to_acquire\"]\n",
    "            clean_output_dict[doc_id] = {}\n",
    "            # extract_skills_dict[doc_id] = {}\n",
    "            # matched_skills_dict[doc_id] = {}\n",
    "            for key in nested_keys:\n",
    "                key_dict = {}\n",
    "                # ext_dict = {}\n",
    "                # match_dict = {}\n",
    "                if key in doc_data:\n",
    "                    key_dict[key] = extract_skills(doc_data[key])\n",
    "                    # key_dict[key], ext_dict[key], match_dict[key] = extract_skills(doc_data[key])\n",
    "                    clean_output_dict[doc_id].update(key_dict)\n",
    "                    # extract_skills_dict[doc_id].update(ext_dict)\n",
    "                    # matched_skills_dict[doc_id].update(match_dict)\n",
    "\n",
    "    return clean_output_dict  # , extract_skills_dict, matched_skills_dict\n",
    "\n",
    "\n",
    "def get_level_3(row):\n",
    "    \"\"\"\n",
    "    Returns the lowest level of the taxonomy that is not NaN in each\n",
    "    \"\"\"\n",
    "    for level in [\"Type Level 3\", \"Type Level 2\", \"Type Level 1\"]:\n",
    "        value = row[level]\n",
    "        if not pd.isna(value):\n",
    "            return value\n",
    "\n",
    "\n",
    "def get_level_2(row):\n",
    "    \"\"\"\n",
    "    Returns the lowest level of the taxonomy that is not NaN in each\n",
    "    \"\"\"\n",
    "    for level in [\"Type Level 2\", \"Type Level 1\"]:\n",
    "        value = row[level]\n",
    "        if not pd.isna(value):\n",
    "            return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in json file\n",
    "df = pd.read_json(\"../../data/annotation/anno_matching.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"doc_type\", \"sample_num\"]\n",
    "job_anno = df[df[\"doc_type\"] == \"job\"].drop(columns=drop_cols)\n",
    "course_anno = df[df[\"doc_type\"] == \"course\"].drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ids = job_anno[\"doc_id\"].astype(str)\n",
    "course_ids = course_anno[\"doc_id\"].astype(str)\n",
    "\n",
    "# output ids as txt files\n",
    "with open(\"anno_job_ids.txt\", \"w\") as f:\n",
    "    for id in job_ids:\n",
    "        f.write(id + \"\\n\")\n",
    "\n",
    "with open(\"anno_course_ids.txt\", \"w\") as f:\n",
    "    for id in course_ids:\n",
    "        f.write(id + \"\\n\")\n",
    "\n",
    "job_ids = job_ids.astype(int)\n",
    "course_ids = course_ids.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python ../skillExtract/pipeline_jobs_courses.py --num-sentences 2 --do-extraction --detailed --max_tokens 2000 --do-matching --prompt_type wlevels --language de --datapath ../data/processed/job_evl_all.csv --candidates_method mixed --max_candidates 3 --ids evaluation/anno_job_ids.txt\n",
    "# !python ../skillExtract/pipeline_jobs_courses.py --num-sentences 2 --do-extraction --detailed --max_tokens 2000 --do-matching --prompt_type wlevels --language de --datapath ../data/processed/course_evl_all.csv --candidates_method mixed --max_candidates 3 --ids evaluation/anno_course_ids.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = pd.read_csv(\"../../data/taxonomy/taxonomy_V4.csv\")\n",
    "taxonomy.drop(columns=[\"name+definition\"], inplace=True)\n",
    "# drop duplicates\n",
    "taxonomy.drop_duplicates(subset=[\"unique_id\", \"name\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxonomy_old = pd.read_csv(\"../../data/taxonomy/taxonomy_V4_simple.csv\")\n",
    "# # check that the unique_id and name are the same\n",
    "# assert taxonomy[\"unique_id\"].equals(taxonomy_old[\"unique_id\"])\n",
    "# assert taxonomy[\"name\"].equals(taxonomy_old[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_anno_exp = job_anno.explode(\"extraction\").reset_index(drop=True)\n",
    "course_anno_exp = course_anno.explode(\"extraction\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "_temp_df = pd.json_normalize(job_anno_exp[\"extraction\"])\n",
    "job_anno_exp = pd.concat([job_anno_exp, _temp_df], axis=1)\n",
    "\n",
    "_temp_df = pd.json_normalize(course_anno_exp[\"extraction\"])\n",
    "course_anno_exp = pd.concat([course_anno_exp, _temp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    \"doc_id\": \"doc_id\",\n",
    "    \"text\": \"extracted\",\n",
    "    \"label.text\": \"level\",\n",
    "    \"req_status\": \"req_status\",\n",
    "    \"match_1\": \"matched\",\n",
    "    # \"match_1s\": \"matched1\",\n",
    "}  # keeping only the first match for now\n",
    "\n",
    "job_anno_exp = job_anno_exp.rename(columns=rename_dict)\n",
    "course_anno_exp = course_anno_exp.rename(columns=rename_dict)\n",
    "\n",
    "# keep only columns in rename_dict value\n",
    "job_anno_exp = job_anno_exp[rename_dict.values()]\n",
    "course_anno_exp = course_anno_exp[rename_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>extracted</th>\n",
       "      <th>level</th>\n",
       "      <th>req_status</th>\n",
       "      <th>matched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15490</td>\n",
       "      <td>Selbständigkeit</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unabhängigkeit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15490</td>\n",
       "      <td>Zuverlässigkeit</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15490</td>\n",
       "      <td>Freude am Umgang mit anderen Menschen</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15490</td>\n",
       "      <td>Teamorientiert</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15490</td>\n",
       "      <td>Schnelle Auffassungsgabe</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>6837</td>\n",
       "      <td>kundenorientiertes Denken</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Kundenorientierung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>6837</td>\n",
       "      <td>Qualitätsbewusstsein</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gewissenhaftigkeit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>6837</td>\n",
       "      <td>interessiert Neues zu lernen</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Lernbereitschaft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>6837</td>\n",
       "      <td>Freude im Umgang mit Kunden</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Kundenorientierung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>6837</td>\n",
       "      <td>Erfahrung im Kundensupport oder im Call Center</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>ICT Service Operation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id                                       extracted    level  \\\n",
       "0     15490                                 Selbständigkeit  Unknown   \n",
       "1     15490                                 Zuverlässigkeit  Unknown   \n",
       "2     15490           Freude am Umgang mit anderen Menschen  Unknown   \n",
       "3     15490                                  Teamorientiert  Unknown   \n",
       "4     15490                        Schnelle Auffassungsgabe  Unknown   \n",
       "..      ...                                             ...      ...   \n",
       "207    6837                       kundenorientiertes Denken  Unknown   \n",
       "208    6837                           Qualitätsbewusstsein   Unknown   \n",
       "209    6837                    interessiert Neues zu lernen  Unknown   \n",
       "210    6837                     Freude im Umgang mit Kunden  Unknown   \n",
       "211    6837  Erfahrung im Kundensupport oder im Call Center  Unknown   \n",
       "\n",
       "    req_status                matched  \n",
       "0      Unknown         Unabhängigkeit  \n",
       "1          NaN                    NaN  \n",
       "2          NaN                    NaN  \n",
       "3          NaN                    NaN  \n",
       "4          NaN                    NaN  \n",
       "..         ...                    ...  \n",
       "207    Unknown     Kundenorientierung  \n",
       "208    Unknown     Gewissenhaftigkeit  \n",
       "209    Unknown       Lernbereitschaft  \n",
       "210    Unknown     Kundenorientierung  \n",
       "211    Unknown  ICT Service Operation  \n",
       "\n",
       "[212 rows x 5 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_anno_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_anno_exp = job_anno_exp.merge(\n",
    "    taxonomy, how=\"left\", left_on=\"matched\", right_on=\"name\"\n",
    ").drop(columns=[\"matched\"])\n",
    "course_anno_exp = course_anno_exp.merge(\n",
    "    taxonomy, how=\"left\", left_on=\"matched\", right_on=\"name\"\n",
    ").drop(columns=[\"matched\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Extraction & Matching results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_file_name = \"course_gpt-3.5-turbo_ids_2sent_n10_mixed_V4_detailed_anno.json\"\n",
    "j_file_name = \"job_gpt-3.5-turbo_ids_2sent_n10_mixed_V4_detailed_anno.json\"\n",
    "path = \"../results/\"\n",
    "\n",
    "with open(path + c_file_name, \"r\") as f:\n",
    "    course_results = json.load(f)\n",
    "\n",
    "with open(path + j_file_name, \"r\") as f:\n",
    "    job_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_matched = get_matched_skills(job_results)\n",
    "course_matched = get_matched_skills(course_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for doc_id, categories in course_matched.items():\n",
    "    for req_status, skills in categories.items():\n",
    "        for skill_id, level, extracted in skills:\n",
    "            processed_data.append(\n",
    "                {\n",
    "                    \"doc_id\": doc_id,\n",
    "                    \"skill_id\": skill_id,\n",
    "                    \"level\": level,\n",
    "                    \"extracted\": extracted,\n",
    "                    \"req_status\": req_status,\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Create DataFrame\n",
    "course_matched_df = pd.DataFrame(processed_data)\n",
    "\n",
    "\n",
    "processed_data = []\n",
    "for doc_id, annotations in job_matched.items():\n",
    "    for skill_id, level, extracted in annotations:\n",
    "        processed_data.append(\n",
    "            {\n",
    "                \"doc_id\": doc_id,\n",
    "                \"skill_id\": skill_id,\n",
    "                \"level\": level,\n",
    "                \"extracted\": extracted,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Create DataFrame\n",
    "job_matched_df = pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_matched_df = job_matched_df.merge(\n",
    "    taxonomy, how=\"left\", left_on=\"skill_id\", right_on=\"unique_id\"\n",
    ").drop(columns=[\"unique_id\"])\n",
    "\n",
    "\n",
    "course_matched_df = course_matched_df.merge(\n",
    "    taxonomy, how=\"left\", left_on=\"skill_id\", right_on=\"unique_id\"\n",
    ").drop(columns=[\"unique_id\"])\n",
    "\n",
    "# convert both ids to int\n",
    "job_matched_df[\"doc_id\"] = job_matched_df[\"doc_id\"].astype(int)\n",
    "course_matched_df[\"doc_id\"] = course_matched_df[\"doc_id\"].astype(int)\n",
    "job_matched_df[\"skill_id\"] = job_matched_df[\"skill_id\"].astype(int)\n",
    "course_matched_df[\"skill_id\"] = course_matched_df[\"skill_id\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Some Metrics\n",
    "\n",
    "### F1 Scores for Matching Results\n",
    "\n",
    "Looking at how well for each document, the final matched result matches the annotations\n",
    "\n",
    "#### Looking at Lowest Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from seqeval.metrics import f1_score as seqeval_f1\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_f1_r_p(\n",
    "    doc_id, anno_df=job_anno_exp, matched_df=job_matched_df, column=\"name\"\n",
    "):\n",
    "    true = list(set(anno_df[anno_df.doc_id == doc_id][column].dropna()))\n",
    "    pred = list(set(matched_df[matched_df.doc_id == doc_id][column].dropna()))\n",
    "    if not true or not pred:\n",
    "        return 0.0, 0.0, 0.0  # or handle it in a way that makes sense for your analysis\n",
    "\n",
    "    # one-hot encode\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    true = mlb.fit_transform([true])\n",
    "    pred = mlb.transform([pred])\n",
    "\n",
    "    f1 = f1_score(true, pred, average=\"micro\")\n",
    "    recall = recall_score(true, pred, average=\"micro\")\n",
    "    precision = precision_score(true, pred, average=\"micro\")\n",
    "\n",
    "    return f1, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB F1 SCORES ON MATCHED SKILLS - LOWEST LEVEL\n",
      "\n",
      "f1: 0.4341832677126795\n",
      "recall: 0.31186628186628185\n",
      "precision: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"JOB F1 SCORES ON MATCHED SKILLS - LOWEST LEVEL\\n\")\n",
    "\n",
    "job_f1_scores = []\n",
    "job_recall_scores = []\n",
    "job_precision_scores = []\n",
    "\n",
    "for job_id in job_ids:\n",
    "    f1, recall, precision = get_acc_f1_r_p(job_id)\n",
    "    job_f1_scores.append(f1)\n",
    "    job_recall_scores.append(recall)\n",
    "    job_precision_scores.append(precision)\n",
    "\n",
    "print(\"f1:\", np.mean(job_f1_scores))\n",
    "print(\"recall:\", np.mean(job_recall_scores))\n",
    "print(\"precision:\", np.mean(job_precision_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COURSE F1 SCORES ON MATCHED SKILLS - LOWEST LEVEL\n",
      "\n",
      "f1: 0.2727272727272727\n",
      "recall: 0.20714285714285713\n",
      "precision: 0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"COURSE F1 SCORES ON MATCHED SKILLS - LOWEST LEVEL\\n\")\n",
    "\n",
    "course_f1_scores = []\n",
    "course_recall_scores = []\n",
    "course_precision_scores = []\n",
    "\n",
    "for course_id in course_ids:\n",
    "    f1, recall, precision = get_acc_f1_r_p(\n",
    "        course_id, anno_df=course_anno_exp, matched_df=course_matched_df\n",
    "    )\n",
    "    course_f1_scores.append(f1)\n",
    "    course_recall_scores.append(recall)\n",
    "    course_precision_scores.append(precision)\n",
    "\n",
    "print(\"f1:\", np.mean(course_f1_scores))\n",
    "print(\"recall:\", np.mean(course_recall_scores))\n",
    "print(\"precision:\", np.mean(course_precision_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy[\"name3\"] = taxonomy.apply(get_level_3, axis=1)\n",
    "taxonomy[\"name2\"] = taxonomy.apply(get_level_2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in name2 and name3 to matched and anno dfs on name\n",
    "\n",
    "job_matched_df = job_matched_df.merge(\n",
    "    taxonomy[[\"name\", \"name2\", \"name3\"]], how=\"left\", on=\"name\"\n",
    ")\n",
    "job_anno_exp = job_anno_exp.merge(\n",
    "    taxonomy[[\"name\", \"name2\", \"name3\"]], how=\"left\", on=\"name\"\n",
    ")\n",
    "\n",
    "course_matched_df = course_matched_df.merge(\n",
    "    taxonomy[[\"name\", \"name2\", \"name3\"]], how=\"left\", on=\"name\"\n",
    ")\n",
    "course_anno_exp = course_anno_exp.merge(\n",
    "    taxonomy[[\"name\", \"name2\", \"name3\"]], how=\"left\", on=\"name\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB F1 SCORES ON MATCHED SKILLS - LEVEL 3\n",
      "\n",
      "f1: 0.45825623178564356\n",
      "recall: 0.3364069264069265\n",
      "precision: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"JOB F1 SCORES ON MATCHED SKILLS - LEVEL 3\\n\")\n",
    "\n",
    "job_f1_scores = []\n",
    "job_recall_scores = []\n",
    "job_precision_scores = []\n",
    "\n",
    "for job_id in job_ids:\n",
    "    f1, recall, precision = get_acc_f1_r_p(\n",
    "        job_id, anno_df=job_anno_exp, matched_df=job_matched_df, column=\"name3\"\n",
    "    )\n",
    "    job_f1_scores.append(f1)\n",
    "    job_recall_scores.append(recall)\n",
    "    job_precision_scores.append(precision)\n",
    "\n",
    "print(\"f1:\", np.mean(job_f1_scores))\n",
    "print(\"recall:\", np.mean(job_recall_scores))\n",
    "print(\"precision:\", np.mean(job_precision_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COURSE F1 SCORES ON MATCHED SKILLS - LEVEL 3\n",
      "\n",
      "f1: 0.2727272727272727\n",
      "recall: 0.20714285714285713\n",
      "precision: 0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"COURSE F1 SCORES ON MATCHED SKILLS - LEVEL 3\\n\")\n",
    "\n",
    "course_f1_scores = []\n",
    "course_recall_scores = []\n",
    "course_precision_scores = []\n",
    "\n",
    "for course_id in course_ids:\n",
    "    f1, recall, precision = get_acc_f1_r_p(\n",
    "        course_id, anno_df=course_anno_exp, matched_df=course_matched_df, column=\"name3\"\n",
    "    )\n",
    "    course_f1_scores.append(f1)\n",
    "    course_recall_scores.append(recall)\n",
    "    course_precision_scores.append(precision)\n",
    "\n",
    "print(\"f1:\", np.mean(course_f1_scores))\n",
    "print(\"recall:\", np.mean(course_recall_scores))\n",
    "print(\"precision:\", np.mean(course_precision_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB F1 SCORES ON MATCHED SKILLS - LEVEL 2\n",
      "\n",
      "f1: 0.650312476194829\n",
      "recall: 0.5422222222222222\n",
      "precision: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"JOB F1 SCORES ON MATCHED SKILLS - LEVEL 2\\n\")\n",
    "\n",
    "job_f1_scores = []\n",
    "job_recall_scores = []\n",
    "job_precision_scores = []\n",
    "\n",
    "for job_id in job_ids:\n",
    "    f1, recall, precision = get_acc_f1_r_p(\n",
    "        job_id, anno_df=job_anno_exp, matched_df=job_matched_df, column=\"name2\"\n",
    "    )\n",
    "    job_f1_scores.append(f1)\n",
    "    job_recall_scores.append(recall)\n",
    "    job_precision_scores.append(precision)\n",
    "\n",
    "print(\"f1:\", np.mean(job_f1_scores))\n",
    "print(\"recall:\", np.mean(job_recall_scores))\n",
    "print(\"precision:\", np.mean(job_precision_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB F1 SCORES ON MATCHED SKILLS - LEVEL 2\n",
      "\n",
      "f1: 0.43499999999999994\n",
      "recall: 0.3975\n",
      "precision: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"COURSE F1 SCORES ON MATCHED SKILLS - LEVEL 2\\n\")\n",
    "\n",
    "course_f1_scores = []\n",
    "course_recall_scores = []\n",
    "course_precision_scores = []\n",
    "\n",
    "for course_id in course_ids:\n",
    "    f1, recall, precision = get_acc_f1_r_p(\n",
    "        course_id, anno_df=course_anno_exp, matched_df=course_matched_df, column=\"name2\"\n",
    "    )\n",
    "    course_f1_scores.append(f1)\n",
    "    course_recall_scores.append(recall)\n",
    "    course_precision_scores.append(precision)\n",
    "\n",
    "print(\"f1:\", np.mean(course_f1_scores))\n",
    "print(\"recall:\", np.mean(course_recall_scores))\n",
    "print(\"precision:\", np.mean(course_precision_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Scores on Extraction Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring back document text for each doc_id\n",
    "course_data = pd.read_csv(\"../../data/processed/course_evl_de.csv\")\n",
    "job_data = pd.read_csv(\"../../data/processed/job_evl_all.csv\")\n",
    "\n",
    "# filter to only ids in anno df\n",
    "course_data = course_data[course_data[\"id\"].isin(course_ids.astype(str))]\n",
    "job_data = job_data[job_data[\"id\"].astype(str).isin(job_ids.astype(str))]\n",
    "\n",
    "job_data[\"id\"] = job_data[\"id\"].astype(int)\n",
    "course_data.id = course_data.id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_job_ids: 15\n",
      "num_course_ids: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"num_job_ids:\", len(job_data[\"id\"].unique()))\n",
    "print(\"num_course_ids:\", len(course_data[\"id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/annadai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "def find_span_in_text(extracted_span, full_text):\n",
    "    # Use fuzzy matching to find the closest match in the text\n",
    "    # Returns the start and end positions of the match\n",
    "    closest_match, _ = process.extractOne(\n",
    "        extracted_span, full_text.split(\".\"), scorer=fuzz.token_set_ratio\n",
    "    )\n",
    "    start = full_text.find(closest_match)\n",
    "    end = start + len(closest_match)\n",
    "    return start, end\n",
    "\n",
    "\n",
    "def tokenize_and_tag(full_text, spans, label_prefix):\n",
    "    tokens = word_tokenize(full_text)\n",
    "    tags = [\"O\"] * len(tokens)\n",
    "\n",
    "    # Function to update tags for a span\n",
    "    def update_tags_for_span(span_start, span_end):\n",
    "        token_index = 0\n",
    "        for i, token in enumerate(tokens):\n",
    "            token_start = full_text.find(token, token_index)\n",
    "            token_end = token_start + len(token)\n",
    "            token_index = token_end\n",
    "            if token_start >= span_end:\n",
    "                break\n",
    "            if span_start <= token_start < span_end:\n",
    "                tags[i] = (\n",
    "                    f\"B-{label_prefix}\"\n",
    "                    if token_start == span_start\n",
    "                    else f\"I-{label_prefix}\"\n",
    "                )\n",
    "\n",
    "    # Update tags for spans\n",
    "    for span_text in spans:\n",
    "        span_start, span_end = find_span_in_text(span_text, full_text)\n",
    "        update_tags_for_span(span_start, span_end)\n",
    "\n",
    "    return list(zip(tokens, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(ids, data, matched_df, anno_df):\n",
    "    \"\"\"Process data for seqeval\"\"\"\n",
    "    tagged_data = {}\n",
    "\n",
    "    for doc_id in ids:\n",
    "        full_text = data[data[\"id\"] == doc_id][\"fulltext\"].values[0]\n",
    "        annotated_spans = matched_df[matched_df[\"doc_id\"] == doc_id][\"extracted\"].values\n",
    "        extracted_spans = anno_df[anno_df[\"doc_id\"] == doc_id][\"extracted\"].values\n",
    "\n",
    "        # Tagging the annotated spans\n",
    "        tagged_annotated = tokenize_and_tag(full_text, annotated_spans, \"ANNOTATED\")\n",
    "\n",
    "        # Tagging the extracted spans\n",
    "        tagged_extracted = tokenize_and_tag(full_text, extracted_spans, \"EXTRACTED\")\n",
    "\n",
    "        # Combine the tagged data for seqeval\n",
    "        tagged_data[doc_id] = (tagged_annotated, tagged_extracted)\n",
    "    return tagged_data\n",
    "\n",
    "\n",
    "def get_seqeval_metrics(tagged_data):\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    for doc_id, (tagged_annotated, tagged_extracted) in tagged_data.items():\n",
    "        doc_true_labels = []\n",
    "        doc_pred_labels = []\n",
    "\n",
    "        # Process annotated spans\n",
    "        for token, tag in tagged_annotated:\n",
    "            label = (\n",
    "                \"B-SKILL\"\n",
    "                if \"B-ANNOTATED\" in tag\n",
    "                else \"I-SKILL\"\n",
    "                if \"I-ANNOTATED\" in tag\n",
    "                else \"O\"\n",
    "            )\n",
    "            doc_true_labels.append(label)\n",
    "\n",
    "        # Process extracted spans\n",
    "        for token, tag in tagged_extracted:\n",
    "            label = (\n",
    "                \"B-SKILL\"\n",
    "                if \"B-EXTRACTED\" in tag\n",
    "                else \"I-SKILL\"\n",
    "                if \"I-EXTRACTED\" in tag\n",
    "                else \"O\"\n",
    "            )\n",
    "            doc_pred_labels.append(label)\n",
    "\n",
    "        true_labels.append(doc_true_labels)\n",
    "        pred_labels.append(doc_pred_labels)\n",
    "\n",
    "    # Import seqeval metrics\n",
    "    from seqeval.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "    # Calculate metrics\n",
    "    f1 = f1_score(true_labels, pred_labels, average=\"micro\")\n",
    "    precision = precision_score(true_labels, pred_labels, average=\"micro\")\n",
    "    recall = recall_score(true_labels, pred_labels, average=\"micro\")\n",
    "\n",
    "    # Print results\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB F1 SCORES ON EXTRACTIONS SEQEVAL\n",
      "\n",
      "f1: 0.6141732283464567\n",
      "precision: 0.7647058823529411\n",
      "recall: 0.5131578947368421\n"
     ]
    }
   ],
   "source": [
    "print(\"JOB F1 SCORES ON EXTRACTIONS SEQEVAL\\n\")\n",
    "\n",
    "job_processed_data = process_data(job_ids, job_data, job_matched_df, job_anno_exp)\n",
    "f1, precision, recall = get_seqeval_metrics(job_processed_data)\n",
    "\n",
    "print(\"f1:\", f1)\n",
    "print(\"precision:\", precision)\n",
    "print(\"recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COURSE F1 SCORES ON EXTRACTIONS SEQEVAL\n",
      "\n",
      "f1: 0.39455782312925175\n",
      "precision: 0.3411764705882353\n",
      "recall: 0.46774193548387094\n"
     ]
    }
   ],
   "source": [
    "print(\"COURSE F1 SCORES ON EXTRACTIONS SEQEVAL\\n\")\n",
    "\n",
    "course_processed_data = process_data(\n",
    "    course_ids, course_data, course_matched_df, course_anno_exp\n",
    ")\n",
    "f1, precision, recall = get_seqeval_metrics(course_processed_data)\n",
    "\n",
    "print(\"f1:\", f1)\n",
    "print(\"precision:\", precision)\n",
    "print(\"recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores on Level Correctness\n",
    "\n",
    "#### Extracted Levels\n",
    "For any correct extraction, look at how many levels are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matched Levels\n",
    "For any correct matches, look at how many levels are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores on Optionality Correctness (Jobs Only)\n",
    "\n",
    "#### Extracted Levels\n",
    "For any correct extraction, look at how many optionality are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matched Levels\n",
    "For any correct matches, look at how many optionality are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
